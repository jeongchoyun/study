[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/생존분석 기본 코드.html",
    "href": "posts/생존분석 기본 코드.html",
    "title": "생존 분석 기본 코드",
    "section": "",
    "text": "library(dplyr)\nlibrary(survival)\nlibrary(moonBook)\nlibrary(survival)\nlibrary(survminer)"
  },
  {
    "objectID": "posts/생존분석 기본 코드.html#no-competing-risk",
    "href": "posts/생존분석 기본 코드.html#no-competing-risk",
    "title": "생존 분석 기본 코드",
    "section": "1. No competing risk",
    "text": "1. No competing risk\n\n1. 데이터 읽기\n\ndata = data.frame(data.table::fread(\"파일명\"))\n\n\n\n2. 데이터 전처리\n\n2.1 날짜형 수정\n\nas.Date(as.character(data1$\"문자형 변수명\"),format=\"%Y%m%d\")\n\n\n\n2.2 범주화\n\n기준이 다른 변수들을 한번에 쉽게 코드화 할 수 있는지 공부하기\n\n\ndata$\"변수명\" = ifelse(data$\"변수명\" == 1 , \"YES\",\"NO\")\ndata$\"변수명\" = factor(data$\"변수명\", levels = c(\"YES\",\"NO\"))\n\n\n\n\n3. Table 1\n\nt1 = tableone::CreateTableOne(vars=c(\"변수명 집합\"),strata = \"기준 변수\",data=data,test=F, addOverall = T)\n# write.csv(print(t1,smd=T),\"AnyC_DTH_t1.csv\")\n\n\n\n4. 중도 절단 고려한 생존기간 설정\n\n# library(survival)\n\nSurv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1)\n\nsummary(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1))\n\n# 특정 시간 생존률\nsummary(survfit(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ \"기준 변수\", data = data), c(1,3)*365.25)\n\n\n\n5. Kaplan-Meiere function\n- 1년 단위 설정\n\nxscale = \"d_y\"\nxtrans &lt;- switch(xscale,\n                 d_m = 12/365.25,\n                 d_y = 1/365.25,\n                 m_d = 365.25/12,\n                 m_y = 1/12,\n                 y_d = 365.25,\n                 y_m =12,\n                 1)\n\nbreaks = seq(0,1250,730)\n\n- 그래프\n\nlibrary(survminer)\n\nggsurvplot(survfit(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ \"기준 변수\",data=data),\n            data= data,\n            fun=\"event\",\n            size=1,\n            palette = c(\"#2E9FDF\",\"#df2e46\"),\n            censor=F,\n            conf.int=T,\n            surv.scale = \"percent\",\n            pval = T,\n            pval.coord = c(0.2, 0.2),\n            xscale = \"d_y\",\n            break.x.by = 365.25*2,\n            xlim = c(0,3700),\n            xlab = \"Years\",\n            ylab = \"Cumulative incidence probability (%)\",\n            legend.labs = c(\"대조군\", \"실험군\"),\n            legend.title = \"Group\",\n            legend = c(0.1, 0.85),\n            risk.table = \"nrisk_cumevents\",\n            risk.table.col=\"기준 변수\",\n            risk.table.height = 0.2)\n            # fontsize = 3,\n            # ggtheme = theme_bw())\n\n\n\n5. Various statistical metrics\n\n5.1 Hazard ratio\n\nAdjusted와 conditional (Unadjusted와 marginal)은 자세히 공부하면 상호교환 가능 단어가 아니라는 논문이 있지만 여기서는 같은 의미로 작성함.\n\n- Unadjusted HR\n\n# library(moonBook)\n\nout = mycph(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ ., data=data)\n\nHRplot(out)\n\ncoef = out\n\npaste0(sprintf(\"%.2f\",coef[row,1]),\"(\", sprintf(\"%.2f\",coef[row,2]),\"-\", sprintf(\"%.2f\",coef[row,3]),\")\")\n\n- Adjusted HR\n\nout2 = coxph(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ ., data=data)\n\nHRplot(out2,show.CI=T)\n\ncoef = summary(out2)$coefficients\n\ncoef[row,2]\n\nexp(coef[row,1]-1.96*coef[row,3])\n\nexp(coef[row,1]+1.96*coef[row,3])\n\npaste0(round(coef[row,2],2),\"(\", round(exp(coef[row,1]-1.96*coef[row,3]),2),\"-\", round(exp(coef[row,1]+1.96*coef[row,3]),2),\")\")\n\n\n\n5.2 p for interaction\n- Unadjusted interaction\n\nfit1 = coxph(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ \"변수1\" + \"변수2\", data = data)\nfit2 = coxph(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ \"변수1\" + \"변수2\" + \"변수1\":\"변수2\", data = data)\ninteraction = anova(fit1, fit2)\ninteraction$`Pr(&gt;|Chi|)`[2]\n\n- Adjusted interaction\n\nfit1 = coxph(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ ., data = data)\nfit2 = coxph(Surv(data$\"생존 시간 변수\", data$\"타겟 변수\" == 1) ~ . + AnyC_:Sex_, data = data)\ninteraction = anova(a, b)\ninteraction$`Pr(&gt;|Chi|)`[2]\n\n\n\n5.3 10000 person-year\n\npy10000 = sum(data[data[,colName]==con,]$\"타겟 변수\") / (sum(as.numeric(data[data[,colName]==con,]$\"생존 시간 변수\")) / 365)*10000\n\n\n\n5.4 SMD\n\ntableone::ExtractSmd(tableone::CreateCatTable(c(\"변수명 집합\"),\"기준 변수\",data=data))"
  },
  {
    "objectID": "posts/생존분석 기본 코드.html#competing-risk",
    "href": "posts/생존분석 기본 코드.html#competing-risk",
    "title": "생존 분석 기본 코드",
    "section": "2. Competing risk",
    "text": "2. Competing risk\n- 경쟁 위험은 타겟 별 원인 변수가 필요함\n- library(cmprsk) crr() 함수\n\nlibrary(cmprsk)\n\n- Subdistribution hazard ratio\n\n# 모델에 들어갈 변수 cbind\ncov.mat = cbind(data$\"변수명\")\n\ncrr.1 = crr(data$\"생존기간 변수\",data$\"원인 별 변수\",cov.mat, failcode = \"관심 원인 값\",cencode=\"중도 절단 값\"))\n\nSubdistribution_coef = summary(crr.1)$coef\n\npaste(Subdistribution_coef[1,2], \"(\", exp(Subdistribution_coef[1,1]-1.96*Subdistribution_coef[1,3]),\"-\", exp(Subdistribution_coef[1,1]+1.96*Subdistribution_coef[1,3]),\")\" )\n\n- cause‐specific hazard ratio\n\ncoxph.1 = coxph(Surv(data$\"생존기간 변수\", data$\"원인 별 변수\" == \"관심 원인 값\") ~ data$\"기준 변수\")\n\ncause_coef = summary(crr.1)$coef\n\npaste(cause_coef[1,2], \"(\", exp(cause_coef[1,1]-1.96*cause_coef[1,3]),\"-\", exp(cause_coef[1,1]+1.96*cause_coef[1,3]),\")\" )\n\n- Cumulative incidence function &gt; 정리 필요\n\ndata$TS = Surv(data$survDt, data$isDTH == 1)\n\n# summary(data$TS)\n\n# summary(survfit(TS~AnyC_,data=data), c(1,3)*365.25)\n\nTSCol = grep(\"TS\",names(data))\n\ncif1 &lt;- cuminc(ftime=data$\"생존기간 변수\",fstatus=data$\"원인 별 변수\", data$\"기준 변수\", cencode=\"중도 절단 값\") \n\nplot(survfit(Surv(data$\"생존시간변수\", data$isDTH == 1) ~ \"기준 변수\", data=data)$time, 1 - survfit(Surv(data$\"생존시간변수\", data$isDTH == 1) ~ \"기준 변수\",data=data)$surv, ylab=\"Probability\")\n\nlines(cif1$`\"기준 변수1\" 1`$time, cif1$`\"기준 변수1\" 1`$est, type=\"l\", ylim=c(0,3), xlab=\"Survival time (days)\",ylab=\"Probability\", lwd = 3, lty=1,col=\"black\") \nlines(cif1$`\"기준 변수2\" 1`$time, cif1$`\"기준 변수2\" 1`$est, type=\"l\", ylim=c(0,0.3), xlab=\"Survival time (days)\",ylab=\"Probability\", lwd = 3, lty=1,col=\"orange\")\n\nlines(cif1$`\"기준 변수1\" 2`$time, cif1$`\"기준 변수1\" 2`$est, type=\"l\", ylim=c(0,0.3), xlab=\"Survival time (days)\",ylab=\"Probability\", lwd = 3, lty=1,col=\"blue\") \nlines(cif1$`\"기준 변수2\" 2`$time, cif1$`\"기준 변수2\" 2`$est, type=\"l\", ylim=c(0,0.3), xlab=\"Survival time (days)\",ylab=\"Probability\", lwd = 3, lty=1,col=\"red\") \n\ntitle(\"Figure 1. Cumulative Incidence functions\")\nlegend(\"topleft\", legend = c(\"All-cause death (1-KM)/Sum of two CIFs\",\"Top5\", \"others\"), lty = c(1,1,1), col = c(\"black\",\"orange\",\"red\"), bty=\"n\")"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/머신러닝기본 코드.html",
    "href": "posts/머신러닝기본 코드.html",
    "title": "머신러닝 기본 코드",
    "section": "",
    "text": "library(tidyverse)\nlibrary(gridExtra)\nlibrary(ROCR)\nlibrary(ggplot2)\nlibrary(MASS)\nlibrary(glmnet)\nlibrary(randomForest)\nlibrary(rpart)\nlibrary(e1071)\nlibrary(nnet)\nlibrary(dplyr)\n\n\n1. 데이터 읽기\n\n# library(tidyverse)\nanal = read.csv(\"파일명\", header = TRUE)  # no missing values\n\n\n512021\n\n\n\n1.1 데이터 확인\n\ndim(anal)\nsummary(anal)\n\n\n\n1.2 결측치 처리\n\n1) 평균화\n\ncols = c(names(anal)[colSums(is.na(anal)) &gt; 0])\ncols\nfor (col in cols) {\n  means &lt;- mean(anal[[col]], na.rm = TRUE)  \n  anal[[col]][is.na(anal[[col]])] &lt;- means\n}\n\n\n'SBP''DBP''HbA1c''Total.Cholesterol''HDL''Hemoglobin''LDL'\n\n\n\nanal1 = anal\nanal1[, 12:length(anal1)] = lapply(anal[, 12:length(anal)], function(x) as.factor(ifelse(x == 0, \"NO\", \"YES\")))\n\n\n\n\n\n2.셋 분할\n\n#-------------------------------------------------------\nset.seed(1)\n\nn = nrow(anal1)\nid = 1:n\ntrain_id = sample(id, n*0.6)\nvalid_id = sample(id[-train_id], n*0.2)\ntest_id = sample(id[-c(train_id, valid_id)])\n\n#-------------------------------------------------------\n\n# x,y가 한 셋이 있는 셋은 데이터프레임 형식으로\ntrain = anal1[train_id,]\nvalidation = anal1[valid_id,]\n\n# x,y가 한 분뢰 있는 셋은 x는 매트릭스,  y는 숫자형\nXX = model.matrix(kidney_yn ~ ., anal1)[,-1]\n\nx_train = XX[train_id,]\ny_train = ifelse(train$kidney_yn == \"YES\", 1, 0)\n\nx_validation = XX[valid_id,]\ny_validation = ifelse(validation$kidney_yn == \"YES\", 1, 0)\n\n\n\n3. 적합\n\n로지스틱 정규화 모형은 X, y 매트릭스 형식\n랜덤포레스트, NN은 X,y가 같이있는 데이터프레임 형식\n\n\nset.seed(1)\n\n# 라쏘\nfit_l1 = cv.glmnet(x_train, y_train, nfolds=10, alpha = 1, family='binomial')\nyhat_l1 = predict(fit_l1, s=\"lambda.1se\", newx= x_validation, type='response')\n\n# EN\nfit_l.5 = cv.glmnet(x_train, y_train, nfolds=10, alpha = 0.5, family='binomial')\nyhat_l.5 = predict(fit_l.5, s=\"lambda.1se\", newx= x_validation, type='response')\n\n# 릿지\nfit_l2 = cv.glmnet(x_train, y_train, nfolds=10, alpha = 0, family='binomial')\nyhat_l2 = predict(fit_l2, s=\"lambda.1se\", newx= x_validation, type='response')\n\n# 랜덤포레스트\nfit_RF = randomForest(kidney_yn ~ . , train)\nyhat_RF = predict(fit_RF, newdata = validation, type = 'prob')[,2]\n\n# SVM\nfit_SVM = svm(kidney_yn ~ ., data=train, gamma=0.001, cost = 10, probability=T)\nyhat_SVM = attr(predict(fit_SVM, newdata=validation, probability = TRUE),\"probabilities\")[,1]\n\n# NN\nfit_NN = nnet(kidney_yn ~ ., train, size=10)\nyhat_NN = predict(fit_NN, newdata=validation, type=\"raw\")\n\n# weights:  221\ninitial  value 1928.754702 \niter  10 value 1552.449084\niter  20 value 1529.381120\niter  30 value 1494.513490\niter  40 value 1472.187084\niter  50 value 1457.636536\niter  60 value 1437.105959\niter  70 value 1426.958487\niter  80 value 1422.342414\niter  90 value 1416.325869\niter 100 value 1408.325402\nfinal  value 1408.325402 \nstopped after 100 iterations\n\n\npng: 2\n\n\n\n\n3. 평가 지표\n\n3.1 이항 편차\n\n# defining binomial deviance function\n\nbinomial_deviance &lt;- function(y_obs, yhat){\n  epsilon = 0.0001\n  yhat = ifelse(yhat &lt; epsilon, epsilon, yhat)\n  yhat = ifelse(yhat &gt; 1-epsilon, 1-epsilon, yhat)\n  a = ifelse(y_obs==0, 0, y_obs * log(y_obs/yhat))\n  b = ifelse(y_obs==1, 0, (1-y_obs) * log((1-y_obs)/(1-yhat)))\n  return(2*sum(a + b))\n}\nbinomial_deviance(y_validation, yhat_l1)\nbinomial_deviance(y_validation, yhat_l.5)\nbinomial_deviance(y_validation, yhat_l2)\nbinomial_deviance(y_validation, yhat_RF)\n\n\n\n3.2 AUC, ROC curve\n\npred_l1 &lt;- prediction(yhat_l1, y_validation)\nperf_l1 &lt;- performance(pred_l1, measure = \"tpr\", x.measure = \"fpr\")\n\npred_l.5 &lt;- prediction(yhat_l.5, y_validation)\nperf_l.5 &lt;- performance(pred_l.5, measure = \"tpr\", x.measure = \"fpr\")\n\npred_l2 &lt;- prediction(yhat_l2, y_validation)\nperf_l2 &lt;- performance(pred_l2, measure = \"tpr\", x.measure = \"fpr\")\n\npred_RF &lt;- prediction(yhat_RF, y_validation)\nperf_RF &lt;- performance(pred_RF, measure = \"tpr\", x.measure = \"fpr\")\n\npred_SVM &lt;- prediction(yhat_SVM, y_validation)\nperf_SVM &lt;- performance(pred_SVM, measure = \"tpr\", x.measure = \"fpr\")\n\npred_NN &lt;- prediction(yhat_NN, y_validation)\nperf_NN &lt;- performance(pred_NN, measure = \"tpr\", x.measure = \"fpr\")\n\n\n# ROC\nplot(perf_l1, col=1, lwd=2, lty = \"solid\",main=\"ROC Curve for different predictive models\")\nplot(perf_l.5, col=2, lwd=2, add=T)\nplot(perf_l2, col=3, lwd=2, add=T)\nplot(perf_RF, col=4, lwd=2, add=T)\nplot(perf_SVM, col=5, lwd=2, add=T)\nplot(perf_NN, col=6, lwd=2, add=T)\nabline(0,1,lty=\"dashed\")\n\n# AUC\nA1=performance(pred_l1, \"auc\")@y.values[[1]]\nA2=performance(pred_l.5, \"auc\")@y.values[[1]]\nA3=performance(pred_l2, \"auc\")@y.values[[1]]\nA4=performance(pred_RF, \"auc\")@y.values[[1]]\nA5=performance(pred_SVM, \"auc\")@y.values[[1]]\nA6=performance(pred_NN, \"auc\")@y.values[[1]]\n\nL1 = c(\"Lasso\", \"EN\" , \"Ridge\" , \"RF\", \"SVM\", \"NN\")\n\n\nL1 = str_pad(L1,width=max(nchar(L1)),side=\"right\")\n\nL2 = format(round(c(A1,A2,A3,A4,A5,A6),4))\n\nL = paste(L1,L2,\" \")\n\n#lty=c(\"solid\",\"f8\",\"longdash\", \"dotdash\",\"dotted\",\"twodash\",\"11\")\n# 'black','red','darkgreen','green','blue','orange','violet'\nlegend(0.55, 0.3, legend=L1,bty=\"n\",\n       col=c(1,2,3,4,5,6), lwd=2)\n\nlegend(0.8, 0.3, legend=paste(\"(\",L2,\")\",sep=\"\"),bty=\"n\")\n\n\n\n3.3 변수 중요도\n\n- 로지스틱 정규화: 계수\n\ncoef(fit_l1, s = fit_l1$lambda.1se)\n\n\n\n\n- 랜덤포레스트: MeanDecreaseGini\n\nfeature_importance = importance(fit_RF)\nvarImpPlot(fit_RF)\nhead(round(feature_importance[order(-feature_importance[,1]), 1, drop=FALSE], 4), n=10)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "study",
    "section": "",
    "text": "머신러닝 기본 코드\n\n\n\n\n\n\n\n\n\n\n\n\n정초윤\n\n\n\n\n\n\n  \n\n\n\n\n생존 분석 기본 코드\n\n\n\n\n\n\n\n\n\n\n\n\n정초윤\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]